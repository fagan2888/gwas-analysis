{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispatching\n",
    "\n",
    "In its simplest form, dispatching involves overloading methods based on their arguments.  Implementations that do this based on argument types like [functools.singledispatch](https://docs.python.org/3/library/functools.html) and [multipledispatch](https://github.com/mrocklin/multipledispatch) make this straightforward.\n",
    "\n",
    "This approach is problematic with duck array types used in functions that take multiple arguments though. A simple example here shows how \\_\\_array_ufunc__ and \\_\\_array_function__ make interoperability between backends possible to an extent, but the backend that ultimately handles an operation is arbitrary (it's the first one that doesn't throw NotImplemented) so the result type will often vary based on the argument order, as does the success of the operation:\n",
    "\n",
    "```python\n",
    "import dask.array as da\n",
    "import sparse\n",
    "a1 = da.array([1, 0])\n",
    "a2 = sparse.COO.from_numpy(np.array([1, 0]))\n",
    "\n",
    "# dask is better at handling arrays from other backends dispatched to ufunc \n",
    "# while sparse only supports sparse or numpy arrays (the first case here\n",
    "# works because dask is applying the function on numpy array chunks)\n",
    "type(a1 + a2) # -> dask.array.core.Array\n",
    "type(a2 + a1) # -> operand type(s) all returned NotImplemented\n",
    "\n",
    "# similarly:\n",
    "a3 = a1.map_blocks(sparse.COO.from_numpy)\n",
    "type(np.stack([a1, a3])) # -> dask.array.core.Array\n",
    "type(np.stack([a3, a1])) # -> All arrays must be instances of SparseArray.\n",
    "type(np.stack([a1, a2])) # -> All arrays must be instances of SparseArray.\n",
    "```\n",
    "\n",
    "This means that code using multipledispatch would need to have overloads that match to each combination of backend types and perform coercion where necessary, likely targeting one of the backends present in the arguments.  Some drawbacks to this are that defining overloads for more than 2 arguments or lists of arrays is hard and that the \"target\" backend is implicit in the implementation rather than controlled by the user.\n",
    "\n",
    "A solution to this proposed in [unumpy](https://github.com/Quansight-Labs/unumpy) (via [uarray](https://github.com/Quansight-Labs/uarray)) is to make the target backend for any numpy functions explicit, as well as provide hooks for coercion of arguments to that backend. This is a good solution for much of the simpler functionality in a genetics toolkit but poses an issue for any more complex domain-specific algorithms in that it would be perfectly reasonable to expect that more than one array backend will be useful for doing things efficiently.  From this perspective, the target implementations become something more like \"algorithms\" than \"backends\" and they should be free to make use of whatever array backends are most beneficial for a particular step (and coercion of arguments is simple when the target backend is clear).  An example would be kinship estimation via CuPy followed by maximal independent set selection using a sparse array backend for relatedness pruning.\n",
    "\n",
    "A further consideration is that dispatch may be something we want to eventually automate, rather than forcing our users to always think about it (e.g. an array with 1% sparsity should not go to an implementation that relies on a sparse backend, tiny arrays should not go to a chunked backend, big dask arrays should not be force into a numpy backend, etc.).\n",
    "\n",
    "This prototype shows a small framework that is based to a degree on uarray and is centered around doing dispatching with all of the following in one place:\n",
    "\n",
    "- **User preferences**: These always get highest priority in choosing an implementation\n",
    "- **Configuration**: This can be scoped with a context manager to fix implementations for a small block of code\n",
    "- **Arguments**: The arrays themselves for type, shape, and content analysis\n",
    "\n",
    "Both uarray and multipledispatch are degenerate cases for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from lib import api\n",
    "xr.set_options(display_style='html');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abstraction consists of a \"Fronted\", a \"Backend\" and an API of stub functions.\n",
    "\n",
    "An example Frontend would look like this where `Frontend` is an internal implementation used by the `MyFrontend` class.  A class like `MyFrontend` would exist for every major piece of functionality in the library that benefits from moderately complex dispatching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This base class is defined once somewhere\n",
    "class Frontend:\n",
    "    \n",
    "    def __init__(self, config: Configuration = None):\n",
    "        self.config = config\n",
    "        self.backends = dict()\n",
    "        \n",
    "    def register(self, backend: Backend) -> None:\n",
    "        # Frontends need to be aware of backends in order to choose intelligently between them\n",
    "        if backend.domain != self.domain:\n",
    "            raise ValueError('Backend with domain {backend.domain} not compatible with frontend domain {self.domain}')\n",
    "        self.backends[backend.id] = backend\n",
    "\n",
    "    def resolve(self, fn: Callable, *args, **kwargs) -> Backend:\n",
    "        # Choose a backend to dispatch to based on as much information as possible:\n",
    "        \n",
    "        # First look for overrides in arguments passed to the function\n",
    "        backend_id = kwargs.get('backend')\n",
    "        \n",
    "        # Next look for overrides in configuration\n",
    "        backend_id = backend_id or self.config.get(str(self.domain.append('backend')))\n",
    "        \n",
    "        # Check to see what if any backends have the required packages installed\n",
    "        backend = [be for be in self.backends.values() if is_compatible(be)]\n",
    "        if backend is None:\n",
    "            raise ValueError(f'No suitable backend found for function {fn.__name__} (domain = {self.domain})')\n",
    "            \n",
    "        # ** Analyze fn/args/kwargs here, in the future **\n",
    "        \n",
    "        return backend\n",
    "\n",
    "    def dispatch(self, fn: Callable, *args, **kwargs):\n",
    "        self.resolve(fn, *args, **kwargs).dispatch(fn, *args, **kwargs)\n",
    "        \n",
    "    def add(self, fn: Callable):\n",
    "        # Wrap a function to be dispatched and preserve docs\n",
    "        @functools.wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return self.dispatch(fn, *args, **kwargs)\n",
    "        return wrapper\n",
    "    \n",
    "# This is defined somewhere close to where the API to dispatch over lives (at least within the same package)\n",
    "class MyFrontend(Frontend):\n",
    "    domain = 'genetics.method'\n",
    "    \n",
    "frontend = MyFrontend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual API methods are simply stubs somewhere that have access to the frontend created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class API:\n",
    "    \n",
    "    @frontend.add\n",
    "    def ld_prune(ds: Dataset) -> Dataset:\n",
    "        \"\"\" All documentation goes here \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backends should be separated from the frontend to make it as easy as possible to isolate imports for their optional dependencies.  They do however need to know which frontend they are associated with and register themselves to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedBackend(Backend):\n",
    "    \n",
    "    domain = 'genetics.method'\n",
    "    id = 'advanced'\n",
    "    \n",
    "    def ld_prune(ds: Dataset) -> Dataset:\n",
    "        # A potential mixed-backend workload:\n",
    "        # - Do pairwise calcs on GPU with CuPy\n",
    "        # - Do variant selection for those in high LD based on sparse arrays\n",
    "        # - Return selected indexes as Dask array with dense numpy chunks\n",
    "        ...\n",
    "        \n",
    "    def requirements() -> Sequence[Requirements]:\n",
    "        return [\n",
    "            # Packages are obvious requirments but this could also eventually include system resource constraints\n",
    "            Requirement('cupy', minimal_version='1.0'),\n",
    "            Requirement('sparse', minimal_version='0.5'),\n",
    "            Requirement('dask') # any version\n",
    "        ]\n",
    "    \n",
    "class SimpleBackend(Backend):\n",
    "    \n",
    "    domain = 'genetics.method'\n",
    "    id = 'simple'\n",
    "    \n",
    "    def ld_prune(ds: Dataset) -> Dataset:\n",
    "        # Do everything assuming numpy\n",
    "        ...\n",
    "\n",
    "# As long as this step is isolated to the module the backend is defined in, it is \n",
    "# easy to make sure that nothing is imported that is not installed:\n",
    "frontend.register(AdvancedBackend())\n",
    "frontend.register(SimpleBackend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage then looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import api\n",
    "\n",
    "ds: Dataset = ...\n",
    "    \n",
    "# Choose the best backend automatically based on environment, config, and arguments\n",
    "# * To start, this is just an arbitrary choice based on which backends have installed dependencies\n",
    "api.ld_prune(ds, backend='auto') \n",
    "\n",
    "\n",
    "# Choose the backend explicitly\n",
    "api.ld_prune(ds, backend='simple')\n",
    "\n",
    "# OR explicitly within a block\n",
    "with api.config.context('genetics.method.backend', 'simple'):    \n",
    "    api.ld_prune(ds)\n",
    "    \n",
    "# OR explicitly globally\n",
    "api.config.set('genetics.method.backend', 'simple')\n",
    "api.ld_prune(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
