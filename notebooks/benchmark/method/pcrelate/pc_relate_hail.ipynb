{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 2.4.4\n",
      "SparkUI available at http://1a8bbd6c6b2b:4041\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.32-a5876a0a2853\n",
      "LOGGING: writing to /home/rav/repos/gwas-analysis/notebooks/benchmark/method/pcrelate/hail-20200417-1505-0.2.32-a5876a0a2853.log\n"
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as pn\n",
    "import matplotlib.pyplot as plt\n",
    "hl.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def write_mt(path: Path, n_samples: int, n_variants: int, n_populations: int) -> None:\n",
    "    mt = hl.balding_nichols_model(n_populations=n_populations, n_samples=n_samples, n_variants=n_variants)\n",
    "    mt.write(path.as_posix(), overwrite=True)\n",
    "    \n",
    "def get_mt(n_samples: int, n_variants: int, n_populations: int) -> hl.MatrixTable:\n",
    "    path_mt = Path(f\"/home/rav/data/tmp/mt_{n_samples}_{n_variants}_{n_populations}.mt\")\n",
    "    if not path_mt.exists():\n",
    "        write_mt(path_mt, n_samples, n_variants, n_populations)\n",
    "    return hl.read_matrix_table(path_mt.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:06:39 Hail: INFO: merging 9 files totalling 976.6K...\n",
      "2020-04-17 15:06:39 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_2000/data.bed\n",
      "  merge time: 19.608ms\n",
      "2020-04-17 15:06:39 Hail: INFO: merging 8 files totalling 48.6K...\n",
      "2020-04-17 15:06:39 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_2000/data.bim\n",
      "  merge time: 11.506ms\n",
      "2020-04-17 15:06:39 Hail: INFO: merging 8 files totalling 32.1K...\n",
      "2020-04-17 15:06:39 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_2000/data.fam\n",
      "  merge time: 11.383ms\n",
      "2020-04-17 15:06:39 Hail: INFO: wrote 2000 variants and 2000 samples to '/home/rav/data/tmp/plink_2000/data'\n",
      "2020-04-17 15:06:42 Hail: INFO: merging 9 files totalling 3.8M...\n",
      "2020-04-17 15:06:42 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_4000/data.bed\n",
      "  merge time: 24.307ms\n",
      "2020-04-17 15:06:42 Hail: INFO: merging 8 files totalling 99.4K...\n",
      "2020-04-17 15:06:42 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_4000/data.bim\n",
      "  merge time: 10.685ms\n",
      "2020-04-17 15:06:43 Hail: INFO: merging 8 files totalling 65.3K...\n",
      "2020-04-17 15:06:43 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_4000/data.fam\n",
      "  merge time: 9.572ms\n",
      "2020-04-17 15:06:43 Hail: INFO: wrote 4000 variants and 4000 samples to '/home/rav/data/tmp/plink_4000/data'\n",
      "2020-04-17 15:06:47 Hail: INFO: merging 9 files totalling 8.6M...\n",
      "2020-04-17 15:06:47 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_6000/data.bed\n",
      "  merge time: 28.061ms\n",
      "2020-04-17 15:06:47 Hail: INFO: merging 8 files totalling 150.2K...\n",
      "2020-04-17 15:06:47 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_6000/data.bim\n",
      "  merge time: 9.475ms\n",
      "2020-04-17 15:06:47 Hail: INFO: merging 8 files totalling 98.5K...\n",
      "2020-04-17 15:06:47 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_6000/data.fam\n",
      "  merge time: 9.464ms\n",
      "2020-04-17 15:06:47 Hail: INFO: wrote 6000 variants and 6000 samples to '/home/rav/data/tmp/plink_6000/data'\n",
      "2020-04-17 15:06:52 Hail: INFO: merging 9 files totalling 15.3M...\n",
      "2020-04-17 15:06:52 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_8000/data.bed\n",
      "  merge time: 39.067ms\n",
      "2020-04-17 15:06:52 Hail: INFO: merging 8 files totalling 201.0K...\n",
      "2020-04-17 15:06:52 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_8000/data.bim\n",
      "  merge time: 8.827ms\n",
      "2020-04-17 15:06:53 Hail: INFO: merging 8 files totalling 131.7K...\n",
      "2020-04-17 15:06:53 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_8000/data.fam\n",
      "  merge time: 8.774ms\n",
      "2020-04-17 15:06:53 Hail: INFO: wrote 8000 variants and 8000 samples to '/home/rav/data/tmp/plink_8000/data'\n",
      "2020-04-17 15:06:59 Hail: INFO: merging 9 files totalling 23.8M...\n",
      "2020-04-17 15:06:59 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_10000/data.bed\n",
      "  merge time: 58.744ms\n",
      "2020-04-17 15:06:59 Hail: INFO: merging 8 files totalling 251.7K...\n",
      "2020-04-17 15:06:59 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_10000/data.bim\n",
      "  merge time: 9.419ms\n",
      "2020-04-17 15:07:00 Hail: INFO: merging 8 files totalling 164.9K...\n",
      "2020-04-17 15:07:00 Hail: INFO: while writing:\n",
      "    /home/rav/data/tmp/plink_10000/data.fam\n",
      "  merge time: 8.987ms\n",
      "2020-04-17 15:07:00 Hail: INFO: wrote 10000 variants and 10000 samples to '/home/rav/data/tmp/plink_10000/data'\n"
     ]
    }
   ],
   "source": [
    "for n in range(2000, 10001, 2000):\n",
    "    mt = get_mt(n, n, 5)\n",
    "    me = mt.key_cols_by()\n",
    "    # we convert to string and add suffix otherwise having int sample ID can break KING (0)\n",
    "    me = me.transmute_cols(sample_idx=\"S\" + hl.str(me.sample_idx))\n",
    "    me = me.key_cols_by(me.sample_idx)\n",
    "    hl.export_plink(me, f\"/home/rav/data/tmp/plink_{n}/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:10:14 Hail: INFO: balding_nichols_model: generating genotypes for 5 populations, 20000 samples, and 20000 variants...\n",
      "2020-04-17 15:10:17 Hail: INFO: Coerced sorted dataset\n",
      "2020-04-17 15:11:14 Hail: INFO: wrote matrix table with 20000 rows and 20000 columns in 8 partitions to /home/rav/data/tmp/mt_20000_20000_5.mt\n",
      "2020-04-17 15:11:23 Hail: INFO: hwe_normalized_pca: running PCA using 20000 variants.\n",
      "2020-04-17 15:11:36 Hail: INFO: pca: running PCA with 10 components...\n",
      "2020-04-17 15:14:27 Hail: INFO: Wrote all 25 blocks of 20000 x 20000 matrix with block size 4096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 14s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:14:29 Hail: INFO: balding_nichols_model: generating genotypes for 5 populations, 40000 samples, and 40000 variants...\n",
      "2020-04-17 15:14:35 Hail: INFO: Coerced sorted dataset\n",
      "2020-04-17 15:19:01 Hail: INFO: wrote matrix table with 40000 rows and 40000 columns in 11 partitions to /home/rav/data/tmp/mt_40000_40000_5.mt\n",
      "2020-04-17 15:19:23 Hail: INFO: hwe_normalized_pca: running PCA using 40000 variants.\n",
      "2020-04-17 15:20:01 Hail: INFO: pca: running PCA with 10 components...\n"
     ]
    }
   ],
   "source": [
    "for n in range(20000, 1000001, 20000):\n",
    "    mt = get_mt(n, n, 5)\n",
    "    # here we assume that there is no recent relatedness in the sample, which should not\n",
    "    # matter for the purpose of the benchmark \n",
    "    %timeit -n 1 -r 1 hl.methods.pc_relate(mt.GT, min_individual_maf=0.01, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
